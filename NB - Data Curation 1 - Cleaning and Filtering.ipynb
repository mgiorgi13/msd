{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Curation Part 1 - Cleaning and Filtering\n",
    "\n",
    "This part filters and cleans the Swiss Dwellings (SD) dataset using the following steps (same as [paper](https://arxiv.org/abs/2407.10121); copy-pasted text):\n",
    "\n",
    "[$\\bullet$] **Feature removal.**\n",
    "All non-floorplan geometries are removed (\\eg \"bathtub\", \"stairs\"; see the full list in the suppl. mat.).\n",
    "\n",
    "[$\\bullet$] **Residential-only filtering.**\n",
    "We remove floor plans that include non-residential-like geometric details (\\eg areas categorized as \"waiting room\", \"dedicated medical room\"; see the full list in the suppl. mat.).\n",
    "This led to the removal of 2,305 (16.6\\%) floor plans.\n",
    "\n",
    "[$\\bullet$] **Near-duplicate removal.**\n",
    "Many floor plans that come from the same building stem from the same plan ID~\\cite{standfest_swiss_2022} (see suppl. mat. for details on ID nesting in SD).\n",
    "Floor plans with the same plan ID are based on the same layout, indicating that the spatial arrangements are nearly identical.\n",
    "Hence, we sample only one-floor plan per plan ID to drastically reduce the amount of near-duplicates.\n",
    "Specifically, we sample the floor plan with the lowest elevation.\n",
    "This led to the removal of 4,395 (31.6\\%) floor plans.\n",
    "\n",
    "[$\\bullet$] **Medium- to large-scale filtering.**\n",
    "Floor plans are removed that contain fewer than 15 areas. In addition, every floor plan should have at least two \"Zone 2\"-categorized areas.\n",
    "This led to the removal of 1,541 (11.1\\%) floor plans.\n",
    "\n",
    "Note that the computation needed for the filtering and cleaning is done in mere seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading and acquiring information\n",
    "\n",
    "You need to download the Swiss Dwellings (SD) `geometries.csv` file here: [SD 3.0.0 (latest version)](https://zenodo.org/records/7788422).\n",
    "\n",
    "We extensively use `Pandas` and `GeoPandas` for filtering and cleaning of the dataset. In the following code block, we load the complete table as a `GeoDataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: geopandas in ./.venv/lib/python3.8/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.8/site-packages (4.67.1)\n",
      "Collecting torch\n",
      "  Using cached torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in ./.venv/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: fiona>=1.8.19 in ./.venv/lib/python3.8/site-packages (from geopandas) (1.10.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.8/site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pyproj>=3.0.1 in ./.venv/lib/python3.8/site-packages (from geopandas) (3.5.0)\n",
      "Requirement already satisfied: shapely>=1.7.1 in ./.venv/lib/python3.8/site-packages (from geopandas) (2.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Using cached triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./.venv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (25.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (2025.1.31)\n",
      "Requirement already satisfied: click~=8.0 in ./.venv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (8.1.8)\n",
      "Requirement already satisfied: click-plugins>=1.0 in ./.venv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in ./.venv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.16.1 fsspec-2025.3.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0\n"
     ]
    }
   ],
   "source": [
    "#install all the required libraries for this notebook\n",
    "!pip install pandas geopandas matplotlib tqdm torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:37:24.520719Z",
     "start_time": "2024-11-29T10:37:11.673394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame as gdf\n",
    "\n",
    "# Path to dataset\n",
    "path = r'./swiss-dwellings-v3.0.0'\n",
    "\n",
    "# Load SD `geometries.csv` as geodataframe\n",
    "DF = gdf(pd.read_csv(os.path.join(path, 'geometries.csv')))\n",
    "DF = DF.rename(columns={'geometry': 'geom'})\n",
    "df = DF.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For an in-depth understanding on the columns, please refer to the [documentation of SD](https://zenodo.org/records/7788422).\n",
    "\n",
    "We print some meta-level information of SD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:37:25.667062Z",
     "start_time": "2024-11-29T10:37:24.512746Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtypes:\n",
      "\t['logistics', 'railing', 'void', 'physio_and_rehabilitation', 'reception_room', 'shaft', 'water_supply', 'air', 'garden', 'basement', 'medical_room', 'carpark', 'warehouse', 'stairs', 'outdoor_void', 'house_technics_facilities', 'arcade', 'garage', 'wall', 'sanitary_rooms', 'living_room', 'room', 'toilet', 'bathroom', 'studio', 'sports_rooms', 'office', 'shower', 'oil_tank', 'common_kitchen', 'balcony', 'dedicated_medical_room', 'storeroom', 'not_defined', 'meeting_room', 'elevator_facilities', 'gas', 'canteen', 'washing_machine', 'window', 'bike_storage', 'vehicle_traffic_area', 'office_space', 'open_plan_office', 'teaching_room', 'foyer', 'transport_shaft', 'shelter', 'column', 'radation_therapy', 'loggia', 'cloakroom', 'kitchen', 'built_in_furniture', 'kitchen_dining', 'waiting_room', 'archive', 'entrance_door', 'pram_and_bike_storage_room', 'sink', 'technical_area', 'corridor', 'community_room', 'bedroom', 'wintergarten', 'dining', 'factory_room', 'elevator', 'operations_facilities', 'heating', 'cold_storage', 'salesroom', 'lobby', 'office_tech_room', 'terrace', 'ramp', 'door', 'workshop', 'break_room', 'bathtub', 'wash_and_dry_room', 'showroom', 'living_dining', 'counter_room', 'basement_compartment', 'pram', 'corridors_and_halls', 'electrical_supply', 'staircase', 'patio', 'lightwell']\n",
      "\n",
      "Types:\n",
      "\t['opening', 'feature', 'separator', 'area']\n",
      "\n",
      "Number of apartments:\t45176\n",
      "Number of sites:\t\t1466\n",
      "Number of buildings:\t3184\n",
      "Number of floors:\t\t13905\n",
      "Number of plans:\t\t8941\n",
      "Number of units:\t\t47285\n",
      "Number of areas:\t\t315037\n",
      "Number of geometries:\t3255905\n"
     ]
    }
   ],
   "source": [
    "# Entity subtypes and types lists\n",
    "entity_subtypes = set(df.entity_subtype)\n",
    "entity_types = set(df.entity_type)\n",
    "\n",
    "# Print information; be aware that subtypes are capitalized in the real dataset\n",
    "print(f'Subtypes:\\n\\t{[cat.lower() for cat in entity_subtypes]}\\n')\n",
    "print(f'Types:\\n\\t{[cat.lower() for cat in entity_types]}\\n')\n",
    "\n",
    "# Print information on dimensions\n",
    "# e.g., Number of distinct apartments, sites, buildings, etc.\n",
    "print(f'Number of apartments:\\t{len(df.apartment_id.unique())}')\n",
    "print(f'Number of sites:\\t\\t{len(df.site_id.unique())}')\n",
    "print(f'Number of buildings:\\t{len(df.building_id.unique())}')\n",
    "print(f'Number of floors:\\t\\t{len(df.floor_id.unique())}')\n",
    "print(f'Number of plans:\\t\\t{len(df.plan_id.unique())}')\n",
    "print(f'Number of units:\\t\\t{len(df.unit_id.unique())}')\n",
    "print(f'Number of areas:\\t\\t{len(df.area_id.unique())}')\n",
    "print(f'Number of geometries:\\t{df.geom.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are most interested in the nesting / tree of (sub)types: I.e., which subtypes are children of which types (parents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:37:27.195689Z",
     "start_time": "2024-11-29T10:37:25.881603Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: opening\n",
      "-- Subtypes:\n",
      "\t['door', 'window', 'entrance_door']\n",
      "\n",
      "Type: feature\n",
      "-- Subtypes:\n",
      "\t['elevator', 'shower', 'stairs', 'kitchen', 'built_in_furniture', 'toilet', 'washing_machine', 'bathtub', 'ramp', 'sink']\n",
      "\n",
      "Type: separator\n",
      "-- Subtypes:\n",
      "\t['wall', 'railing', 'column']\n",
      "\n",
      "Type: area\n",
      "-- Subtypes:\n",
      "\t['logistics', 'void', 'physio_and_rehabilitation', 'reception_room', 'shaft', 'water_supply', 'air', 'garden', 'basement', 'medical_room', 'carpark', 'warehouse', 'outdoor_void', 'house_technics_facilities', 'arcade', 'garage', 'sanitary_rooms', 'living_room', 'room', 'bathroom', 'studio', 'sports_rooms', 'office', 'oil_tank', 'common_kitchen', 'balcony', 'dedicated_medical_room', 'storeroom', 'not_defined', 'meeting_room', 'elevator_facilities', 'gas', 'canteen', 'bike_storage', 'vehicle_traffic_area', 'office_space', 'open_plan_office', 'teaching_room', 'foyer', 'transport_shaft', 'shelter', 'radation_therapy', 'loggia', 'cloakroom', 'kitchen', 'kitchen_dining', 'waiting_room', 'archive', 'pram_and_bike_storage_room', 'technical_area', 'corridor', 'community_room', 'bedroom', 'wintergarten', 'factory_room', 'dining', 'elevator', 'operations_facilities', 'heating', 'cold_storage', 'salesroom', 'lobby', 'office_tech_room', 'terrace', 'workshop', 'break_room', 'wash_and_dry_room', 'showroom', 'living_dining', 'counter_room', 'basement_compartment', 'pram', 'corridors_and_halls', 'electrical_supply', 'staircase', 'patio', 'lightwell']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity_type in entity_types:\n",
    "    print(f'Type: {entity_type}\\n'\n",
    "          f'-- Subtypes:\\n\\t{[cat.lower() for cat in set(df[df[\"entity_type\"]==entity_type].entity_subtype)]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature removal\n",
    "\n",
    "This step is one of the most delicate steps of the process. It comes from the fact that there are two equivalently named *subtypes* that have a different *type* category. For the 'feature' and 'area' types, subtypes can be both 'KITCHEN' and 'ELEVATOR'. We first remove these two categories from the 'feature' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:37:28.459064Z",
     "start_time": "2024-11-29T10:37:27.391967Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[~(df['entity_type'] == 'feature')]\n",
    "df = df[~(df['entity_subtype'] == 'RAILING')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Residential-only filtering\n",
    "\n",
    "We remove floors that have at least one of the following subtypes:\n",
    "\n",
    "```python\n",
    "{'OFFICE', 'WASH_AND_DRY_ROOM', 'VEHICLE_TRAFFIC_AREA', 'BASEMENT', 'WAITING_ROOM',\n",
    "'MEDICAL_ROOM', 'CANTEEN', 'SALESROOM', 'COLD_STORAGE', 'WORKSHOP', 'OUTDOOR_VOID',\n",
    "'TECHNICAL_AREA', 'DEDICATED_MEDICAL_ROOM', 'WAREHOUSE', 'GARDEN', 'PRAM_AND_BIKE_STORAGE_ROOM',\n",
    "'OFFICE_SPACE', 'SHOWROOM', 'AIR', 'PRAM', 'SANITARY_ROOMS', 'LOBBY', 'WATER_SUPPLY', 'HEATING',\n",
    " 'LOGGIA', 'OIL_TANK', 'GAS', 'PATIO', 'FOYER', 'OPEN_PLAN_OFFICE', 'SHELTER', 'SPORTS_ROOMS',\n",
    " 'HOUSE_TECHNICS_FACILITIES', 'TEACHING_ROOM', 'OFFICE_TECH_ROOM', 'WINTERGARTEN', 'CLOAKROOM',\n",
    " 'RECEPTION_ROOM', 'CARPARK', 'STUDIO', 'NOT_DEFINED', 'COMMUNITY_ROOM',\n",
    " 'PHYSIO_AND_REHABILITATION', 'FACTORY_ROOM', 'ARCHIVE', 'OPERATIONS_FACILITIES', 'ARCADE',\n",
    " 'LOGISTICS', 'TRANSPORT_SHAFT', 'GARAGE', 'COUNTER_ROOM', 'BREAK_ROOM', 'ELECTRICAL_SUPPLY',\n",
    " 'ELEVATOR_FACILITIES', 'MEETING_ROOM', 'COMMON_KITCHEN', 'BASEMENT_COMPARTMENT', 'LIGHTWELL',\n",
    " 'BIKE_STORAGE', 'RADATION_THERAPY'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:37:31.739175Z",
     "start_time": "2024-11-29T10:37:30.554946Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted floors:\t2305\n",
      "Number of remaining floors:\t11600\n"
     ]
    }
   ],
   "source": [
    "from constants import ZONING_MAPPING\n",
    "\n",
    "# Entity subtypes for which the floors should be completely removed\n",
    "subtypes_to_remove = set(df.entity_subtype) - set(list(ZONING_MAPPING.keys()))\n",
    "\n",
    "# Find floor ids of non- or mixed-residential\n",
    "mixed_floor_ids = set(df[df['entity_subtype'].isin(set(subtypes_to_remove))].floor_id)\n",
    "res_floor_ids = set(df.floor_id) - mixed_floor_ids  # The complement of the other\n",
    "\n",
    "# Filter on residential-only floor ids\n",
    "df = df[df['floor_id'].isin(res_floor_ids)].reset_index(drop=True)\n",
    "\n",
    "# If you run it again; there won't, obviously, be any floor plans to-be-removed !\n",
    "print(f'Number of deleted floors:\\t{len(mixed_floor_ids)}')\n",
    "print(f'Number of remaining floors:\\t{len(df.floor_id.unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Near-duplicate removal\n",
    "\n",
    "We remove what we would like to call *near* duplicates.\n",
    "It is important to not have too similar instances in the machine learning dataset because two (or more) of the same signals and annotations will never help (and will only hinder) training and might even cause imbalanced model behavior (usually per epoch the whole dataset is seen once; hence if there are duplicates the model will better learn on those instances) and unfair evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:40:26.634797Z",
     "start_time": "2024-11-29T10:40:25.886981Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining floors: 7205\n"
     ]
    }
   ],
   "source": [
    "one_per_plan_floor_ids = df.sort_values('elevation').groupby('plan_id').head(1)['floor_id'].values\n",
    "df = df[df['floor_id'].isin(one_per_plan_floor_ids)]\n",
    "\n",
    "# after plan id selection\n",
    "print(f'Number of remaining floors: {df.floor_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Medium- to large-scale filtering\n",
    "\n",
    "Floor plans are removed that contain fewer than 15 areas. In addition, every floor plan should have at least two \"Zone 2\"-categorized areas.\n",
    "This led to the removal of 1,541 (11.1\\%) floor plans.\n",
    "\n",
    "We first add two extra columns to the dataframe: One indicating the *zoning type* of the room; the other the *room type*.\n",
    "See `constants.py` for the zoning and room type categories and mappings between them and the (original) subtype categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:46:21.476207Z",
     "start_time": "2024-11-29T10:46:21.246990Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from constants import ROOM_MAPPING\n",
    "\n",
    "df['zoning'] = df['entity_subtype'].map(ZONING_MAPPING)\n",
    "df['roomtype'] = df['entity_subtype'].map(ROOM_MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we find all the floor identities (IDs) that consist of a minimum of 15 rooms and have at least 2 rooms of type `Zone 2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:49:47.526620Z",
     "start_time": "2024-11-29T10:49:28.567949Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/Github/msd/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 7205/7205 [00:20<00:00, 347.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "floor_ids = df.floor_id.unique()\n",
    "\n",
    "min_nr_areas = 15\n",
    "min_nr_zone2 = 2\n",
    "\n",
    "# Initialize empty list\n",
    "floor_ids_at_scale = []\n",
    "\n",
    "# Takes a couple of seconds\n",
    "for floor_id in tqdm(floor_ids):\n",
    "\n",
    "    df_floor = df[df.floor_id == floor_id].reset_index(drop=True)\n",
    "    df_floor = df_floor[df_floor.zoning.isin(['Zone1', 'Zone2', 'Zone3', 'Zone4'])]\n",
    "    df_zone2 = df_floor[df_floor.zoning.isin(['Zone2'])]\n",
    "\n",
    "    # Compute number of rooms and those with type Zone 2\n",
    "    nr_areas = len(df_floor.zoning.values)\n",
    "    nr_zone2 = len(df_zone2.zoning.values)\n",
    "\n",
    "    # Filter on minimum number of areas and minimum number of Zone 2\n",
    "    if nr_areas >= min_nr_areas and nr_zone2 >= min_nr_zone2:\n",
    "        floor_ids_at_scale.append(floor_id)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And filter the dataframe based on these IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:50:48.586012Z",
     "start_time": "2024-11-29T10:50:48.221186Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of floors: 5664\n"
     ]
    }
   ],
   "source": [
    "# remove small complexes\n",
    "df = df[df['floor_id'].isin(floor_ids_at_scale)].reset_index(drop=True)\n",
    "\n",
    "# after removal of selection\n",
    "print(f'Final number of floors: {df.floor_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Saving the dataframe\n",
    "\n",
    "You can now save the cleaned and filtered dataframe anywhere that you like.\n",
    "In our GitHub, you can find it back under the folder `data`, saved as `f\"MSD 5.664k (V1).csv\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T10:56:24.906350Z",
     "start_time": "2024-11-29T10:56:08.663859Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "df.to_csv(f'data/MSD {len(set(df.floor_id))/1000:.3f}k (V1).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
